
function alphaDVN_target_single_bao(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)

    alphas = map(eachcol(ğ’Ÿ[:s])) do s
        @assert length(s) == 2
        b = convert_s(DiscreteBelief, collect(s), mdp)

        Î“a = Vector{Vector{Float32}}(undef, length(A))

        not_terminals = [stateindex(pomdp, s) for s in S if !isterminal(pomdp, s)]
        terminals = [stateindex(pomdp, s) for s in S if isterminal(pomdp, s)]
        for a in A
            Î“ao = Vector{Vector{Float32}}(undef, length(O))
            trans_probs = dropdims(sum([pdf(transition(pomdp, S[is], a), sp) * b.b[is] for sp in S, is in not_terminals], dims=2), dims=2)
            if !isempty(terminals) trans_probs[terminals] .+= b.b[terminals] end

            for o in O
                # update beliefs
                obs_probs = pdf.(map(sp -> observation(pomdp, a, sp), S), [o])
                bâ€² = obs_probs .* trans_probs

                if sum(bâ€²) > 0.
                    bâ€² = DiscreteBelief(pomdp, b.state_list, belief_norm(pomdp, b.b, bâ€², terminals, not_terminals))
                else
                    bâ€² = DiscreteBelief(pomdp, b.state_list, zeros(length(S)))
                end

                # extract optimal alpha vector at resulting belief
                # Î“ao[obsindex(pomdp, o)] = _argmax(Î± -> dot(Î±,bâ€².b), Î“)
                bao_vec = convert_s(Vector, bâ€², mdp)
                Î“ao[obsindex(pomdp, o)] = value(Ï€, bao_vec)
            end

            # construct new alpha vectors
            Î“a[actionindex(pomdp, a)] = [r(s, a) + (!isterminal(pomdp, s) ? (Î³ * sum(pdf(transition(pomdp, s, a), sp) * pdf(observation(pomdp, s, a, sp), o) * Î“ao[i][j]
                                            for (j, sp) in enumerate(S), (i, o) in enumerate(O))) : 0.)
                                            for s in S]
        end

        # find the optimal alpha vector
        idx = argmax(map(Î±a -> Î±a â‹… b.b, Î“a))
        alphavec = AlphaVec(Î“a[idx], A[idx])
        return alphavec.alpha
    end
    reduce(hcat, alphas)
end

function alphaDVN_target_all_bao(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)

    alphas = map(eachcol(ğ’Ÿ[:s])) do s
        @assert length(s) == 2
        b = convert_s(DiscreteBelief, collect(s), mdp)

        not_terminals = [stateindex(pomdp, s) for s in S if !isterminal(pomdp, s)]
        terminals = [stateindex(pomdp, s) for s in S if isterminal(pomdp, s)]

        Î“net = Vector{Vector{Float64}}(undef, length(A) * length(O))
        i = 1
        for a in A
            trans_probs = dropdims(sum([pdf(transition(pomdp, S[is], a), sp) * b.b[is] for sp in S, is in not_terminals], dims=2), dims=2)
            if !isempty(terminals) trans_probs[terminals] .+= b.b[terminals] end

            for o in O
                # update beliefs
                obs_probs = pdf.(map(sp -> observation(pomdp, a, sp), S), [o])
                bâ€² = obs_probs .* trans_probs

                if sum(bâ€²) > 0.
                    bâ€² = DiscreteBelief(pomdp, b.state_list, belief_norm(pomdp, b.b, bâ€², terminals, not_terminals))
                else
                    bâ€² = DiscreteBelief(pomdp, b.state_list, zeros(length(S)))
                end

                # extract optimal alpha vector at resulting belief
                # Î“ao[obsindex(pomdp, o)] = _argmax(Î± -> dot(Î±,bâ€².b), Î“)
                bao_vec = convert_s(Vector, bâ€², mdp)
                Î“net[i] = value(Ï€, bao_vec)
                i += 1
            end
        end

        Î“a = Vector{Vector{Float32}}(undef, length(A))
        for a in A
            Î“ao = Vector{Vector{Float32}}(undef, length(O))
            trans_probs = dropdims(sum([pdf(transition(pomdp, S[is], a), sp) * b.b[is] for sp in S, is in not_terminals], dims=2), dims=2)
            if !isempty(terminals) trans_probs[terminals] .+= b.b[terminals] end

            for o in O
                # update beliefs
                obs_probs = pdf.(map(sp -> observation(pomdp, a, sp), S), [o])
                bâ€² = obs_probs .* trans_probs

                if sum(bâ€²) > 0.
                    bâ€² = DiscreteBelief(pomdp, b.state_list, belief_norm(pomdp, b.b, bâ€², terminals, not_terminals))
                else
                    bâ€² = DiscreteBelief(pomdp, b.state_list, zeros(length(S)))
                end

                # extract optimal alpha vector at resulting belief
                Î“ao[obsindex(pomdp, o)] = _argmax(Î± -> dot(Î±,bâ€².b), Î“net)
            end

            # construct new alpha vectors
            Î“a[actionindex(pomdp, a)] = [r(s, a) + (!isterminal(pomdp, s) ? (Î³ * sum(pdf(transition(pomdp, s, a), sp) * pdf(observation(pomdp, s, a, sp), o) * Î“ao[i][j]
                                            for (j, sp) in enumerate(S), (i, o) in enumerate(O))) : 0.)
                                            for s in S]
        end

        # find the optimal alpha vector
        idx = argmax(map(Î±a -> Î±a â‹… b.b, Î“a))
        alphavec = AlphaVec(Î“a[idx], A[idx])
        return alphavec.alpha
    end
    reduce(hcat, alphas)
end

function alphaDVN_sampleTarget(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)
    ns = length(S)

    alphas = map(eachcol(ğ’Ÿ[:s])) do s
        @assert length(s) == 2
        B = statetype(mdp)
        b = convert_s(B, collect(s), mdp)

        Î“a = Vector{Vector{Float32}}(undef, length(A))

        not_terminals = [stateindex(pomdp, s) for s in S if !isterminal(pomdp, s)]
        terminals = [stateindex(pomdp, s) for s in S if isterminal(pomdp, s)]
        for a in A
            Î“ao = Vector{Vector{Float32}}(undef, length(O))
            trans_probs = dropdims(sum([pdf(transition(pomdp, S[is], a), sp) * b.b[is] for sp in S, is in not_terminals], dims=2), dims=2)
            if !isempty(terminals) trans_probs[terminals] .+= b.b[terminals] end

            for o in O
                # update beliefs
                obs_probs = pdf.(map(sp -> observation(pomdp, a, sp), S), [o])
                bâ€² = obs_probs .* trans_probs

                if sum(bâ€²) > 0.
                    bâ€² = DiscreteBelief(pomdp, b.state_list, belief_norm(pomdp, b.b, bâ€², terminals, not_terminals))
                else
                    bâ€² = DiscreteBelief(pomdp, b.state_list, zeros(ns))
                end

                # extract optimal alpha vector at resulting belief
                # Î“ao[obsindex(pomdp, o)] = _argmax(Î± -> dot(Î±,bâ€².b), Î“)
                bao_vec = convert_s(Vector, bâ€², mdp)
                Î“ao[obsindex(pomdp, o)] = value(Ï€, bao_vec)
            end

            # construct new alpha vectors
            Î“a[actionindex(pomdp, a)] = zeros(length(S))
            for s in S
                for _ in 1:Ï€.m
                    sp, o, r = @gen(:sp,:o,:r)(pomdp, s, a)
                    Î±o = Î“ao[obsindex(pomdp, o)]
                    v = r + (!isterminal(pomdp, s) ? (Î³ * Î±o[stateindex(pomdp, sp)]) : 0.)
                    Î“a[actionindex(pomdp, a)][stateindex(pomdp, s)] += v / Ï€.m
                end
            end
        end

        # find the optimal alpha vector
        idx = argmax(map(Î±a -> Î±a â‹… b.b, Î“a))
        alphavec = AlphaVec(Î“a[idx], A[idx])
        return alphavec.alpha
    end
    reduce(hcat, alphas)
end

function alphaDVN_weightedSampleTarget(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)
    ns = length(S)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:o]))) do (s, ovec)
        @assert length(s) == 2
        b = convert_s(statetype(mdp), collect(s), mdp)
        o = convert_o(obstype(pomdp), collect(ovec), mdp.pomdp)

        Î“a = Vector{Vector{Float32}}(undef, length(A))

        not_terminals = [stateindex(pomdp, s) for s in S if !isterminal(pomdp, s)]
        terminals = [stateindex(pomdp, s) for s in S if isterminal(pomdp, s)]
        for a in A
            # Î“ao = Vector{Vector{Float32}}(undef, length(O))
            trans_probs = dropdims(sum([pdf(transition(pomdp, S[is], a), sp) * b.b[is] for sp in S, is in not_terminals], dims=2), dims=2)
            if !isempty(terminals) trans_probs[terminals] .+= b.b[terminals] end

            # update beliefs
            obs_probs = pdf.(map(sp -> observation(pomdp, a, sp), S), [o])
            bâ€² = obs_probs .* trans_probs

            if sum(bâ€²) > 0.
                bâ€² = DiscreteBelief(pomdp, b.state_list, belief_norm(pomdp, b.b, bâ€², terminals, not_terminals))
            else
                bâ€² = DiscreteBelief(pomdp, b.state_list, zeros(ns))
            end

            # extract optimal alpha vector at resulting belief
            # Î“ao[obsindex(pomdp, o)] = _argmax(Î± -> dot(Î±,bâ€².b), Î“)
            bao_vec = convert_s(Vector, bâ€², mdp)
            Î±o = value(Ï€, bao_vec)

            # construct new alpha vectors
            Î“a[actionindex(pomdp, a)] = zeros(length(S))
            for s in S
                if !isterminal(pomdp, s)
                    w_sum = 0.0
                    for _ in 1:Ï€.m
                        sp = @gen(:sp)(pomdp, s, a)
                        w = obs_weight(pomdp, s, a, sp, o)
                        v = w * Î±o[stateindex(pomdp, sp)]
                        w_sum += w
                        Î“a[actionindex(pomdp, a)][stateindex(pomdp, s)] += v
                    end
                    Î“a[actionindex(pomdp, a)][stateindex(pomdp, s)] *= Î³ / w_sum
                end
                Î“a[actionindex(pomdp, a)][stateindex(pomdp, s)] += r(s, a)
            end
        end

        # find the optimal alpha vector
        idx = argmax(map(Î±a -> Î±a â‹… b.b, Î“a))
        alphavec = AlphaVec(Î“a[idx], A[idx])
        return alphavec.alpha
    end
    reduce(hcat, alphas)
end

function alphaDVN_modelFreeStateBackups(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    r = StateActionReward(pomdp)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:o]))) do (svec, ovec)
        @assert length(svec) == 2
        B = statetype(mdp)
        b = convert_s(B, collect(svec), mdp)
        o = convert_o(obstype(pomdp), collect(ovec), mdp.pomdp)

        Î“a = Vector{Vector{Float32}}(undef, length(A))
        for a in A
            # construct new alpha vectors
            Î± = zeros(length(S))
            for s in S
                s_base = zeros(length(S))
                s_base[stateindex(pomdp, s)] = 1.
                bs = convert_s(B, s_base, mdp)
                bp = POMDPs.update(mdp.updater, bs, a, o)
                Î±s = value(Ï€, convert_s(Vector, bp, mdp))
                bpvec = convert_s(Vector, bp, mdp)
                v = r(s, a) + (!isterminal(pomdp, s) ? (Î³ * dot(bpvec, Î±s)) : 0.)
                Î±[stateindex(pomdp, s)] = v
            end
            Î“a[actionindex(pomdp, a)] = Î±
        end

        # find the optimal alpha vector
        idx = argmax(map(Î±a -> Î±a â‹… b.b, Î“a))
        alphavec = AlphaVec(Î“a[idx], A[idx])
        return alphavec.alpha
    end
    reduce(hcat, alphas)
end

function alphaDVN_modelFreeWeightedStateBackups(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    r = StateActionReward(pomdp)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:o]))) do (svec, ovec)
        @assert length(svec) == 2
        B = statetype(mdp)
        b = convert_s(B, collect(svec), mdp)
        o = convert_o(obstype(pomdp), collect(ovec), mdp.pomdp)

        Î“a = Vector{Vector{Float32}}(undef, length(A))
        for a in A
            # construct new alpha vectors
            Î± = zeros(length(S))
            for s in S
                s_base = zeros(length(S))
                s_base[stateindex(pomdp, s)] = 1.
                bs = convert_s(B, s_base, mdp)
                bp = POMDPs.update(mdp.updater, bs, a, o)
                Î±s = value(Ï€, convert_s(Vector, bp, mdp))
                bpvec = convert_s(Vector, bp, mdp)
                v = r(s, a) + (!isterminal(pomdp, s) ? (Î³ * dot(bpvec, Î±s)) : 0.)
                Î±[stateindex(pomdp, s)] = v
            end
            Î± = svec .* Î± + (1 .- svec) .* value(Ï€, svec)
            Î“a[actionindex(pomdp, a)] = Î±
        end

        # find the optimal alpha vector
        idx = argmax(map(Î±a -> Î±a â‹… b.b, Î“a))
        alphavec = AlphaVec(Î“a[idx], A[idx])
        return alphavec.alpha
    end
    reduce(hcat, alphas)
end

function alphaDVN_modelFreeBeliefBackup(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    r = StateActionReward(pomdp)

    alphas = map(eachcol(ğ’Ÿ[:s])) do bvec
        @assert length(bvec) == 2 string(bvec)
        B = statetype(mdp)
        b = convert_s(B, collect(bvec), mdp)

        Î“a = Vector{Vector{Float32}}(undef, length(A))
        for a in A
            # construct new alpha vectors
            Î±a = zeros(length(S))

            o = @gen(:o)(pomdp, rand(b), a)
            bp = POMDPs.update(mdp.updater, b, a, o)
            bpvec = convert_s(Vector, bp, mdp)
            Î±_bp  = value(Ï€, bpvec)
            for s in S
                idx = stateindex(pomdp, s)
                is = abs(bvec[idx]) < sqrt(eps()) ? 0. : (bpvec[idx] / bvec[idx])
                v = r(s,a) + (!isterminal(pomdp, s) ? (Î³ * is * Î±_bp[idx]) : 0.)
                Î±a[stateindex(pomdp, s)] = v
            end
            Î“a[actionindex(pomdp, a)] = Î±a
        end

        # find the optimal alpha vector
        idx = argmax(map(Î±a -> Î±a â‹… b.b, Î“a))
        alphavec = AlphaVec(Î“a[idx], A[idx])
        return alphavec.alpha
    end
    reduce(hcat, alphas)
end

function alphaDVN_modelFreeWeightedBeliefBackup(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    r = StateActionReward(pomdp)

    alphas = map(eachcol(ğ’Ÿ[:s])) do bvec
        @assert length(bvec) == 2 string(bvec)
        B = statetype(mdp)
        b = convert_s(B, collect(bvec), mdp)

        Î“a = Vector{Vector{Float32}}(undef, length(A))
        for a in A
            # construct new alpha vectors
            Î±a = zeros(length(S))

            o = @gen(:o)(pomdp, rand(b), a)
            bp = POMDPs.update(mdp.updater, b, a, o)
            bpvec = convert_s(Vector, bp, mdp)
            Î±_bp  = value(Ï€, bpvec)
            for s in S
                idx = stateindex(pomdp, s)
                is = abs(bvec[idx]) < sqrt(eps()) ? 0. : (bpvec[idx] / bvec[idx])
                v = r(s,a) + (!isterminal(pomdp, s) ? (Î³ * is * Î±_bp[idx]) : 0.)
                Î±a[stateindex(pomdp, s)] = v
            end
            Î±a = bvec .* Î±a + (1 .- bvec) .* value(Ï€, bvec)

            Î“a[actionindex(pomdp, a)] = Î±a
        end

        # find the optimal alpha vector
        idx = argmax(map(Î±a -> Î±a â‹… b.b, Î“a))
        alphavec = AlphaVec(Î“a[idx], A[idx])
        return alphavec.alpha
    end
    reduce(hcat, alphas)
end
