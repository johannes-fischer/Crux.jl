
function alphaDQN_target(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)
    ns = length(S)
    na = length(A)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]))) do (s, a_oh)
        b = convert_s(DiscreteBelief, collect(s), mdp)

        @assert length(s) == length(states(pomdp))
        @assert length(a_oh) == length(actions(pomdp))

        not_terminals = [stateindex(pomdp, s) for s in S if !isterminal(pomdp, s)]
        terminals = [stateindex(pomdp, s) for s in S if isterminal(pomdp, s)]

        a = A[argmax(a_oh)]

        Î“ao = Vector{Vector{Float32}}(undef, length(O))
        trans_probs = dropdims(sum([pdf(transition(pomdp, S[is], a), sp) * b.b[is] for sp in S, is in not_terminals], dims=2), dims=2)
        if !isempty(terminals) trans_probs[terminals] .+= b.b[terminals] end

        for o in O
            # update beliefs
            obs_probs = pdf.(map(sp -> observation(pomdp, a, sp), S), [o])
            bâ€² = obs_probs .* trans_probs

            if sum(bâ€²) > 0.
                bâ€² = DiscreteBelief(pomdp, b.state_list, belief_norm(pomdp, b.b, bâ€², terminals, not_terminals))
            else
                bâ€² = DiscreteBelief(pomdp, b.state_list, zeros(length(S)))
            end

            # extract optimal alpha vector at resulting belief
            # Î“ao[obsindex(pomdp, o)] = _argmax(Î± -> dot(Î±,bâ€².b), Î“)
            bao_vec = convert_s(Vector, bâ€², mdp)
            Î±Q = reshape(value(Ï€.Ï€, bao_vec), (ns, na))
            idx = argmax(map(Î±a -> Î±a â‹… bao_vec, eachcol(Î±Q)))
            # alphavec = AlphaVec(Î“a[idx], A[idx])
            # idx = argmax(reshape(bao_vec * Î±Q, na))
            Î“ao[obsindex(pomdp, o)] = Î±Q[:, idx]
        end

        # construct new alpha vectors
        Î± = Float32[r(s, a) + (!isterminal(pomdp, s) ? (Î³ * sum(pdf(transition(pomdp, s, a), sp) * pdf(observation(pomdp, s, a, sp), o) * Î“ao[i][j]
                                        for (j, sp) in enumerate(S), (i, o) in enumerate(O))) : 0.)
                                        for s in S]

        # find the optimal alpha vector
        # idx = argmax(map(Î±a -> Î±a â‹… b.b, Î“a))
        # alphavec = AlphaVec(Î“a[idx], A[idx])
        return Î±
    end
    res = reduce(hcat, alphas)
    reshaped = reshape(res, (length(S), 1, length(alphas)))

    reshaped
end

function alphaDQN_targetImpSamp(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)
    ns = length(S)
    na = length(A)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]))) do (bvec, a_oh)
        b = convert_s(DiscreteBelief, collect(bvec), mdp)

        @assert length(bvec) == length(states(pomdp))
        @assert length(a_oh) == length(actions(pomdp))

        not_terminals = [stateindex(pomdp, s) for s in S if !isterminal(pomdp, s)]
        terminals = [stateindex(pomdp, s) for s in S if isterminal(pomdp, s)]

        a = A[argmax(a_oh)]

        Î“ao = Vector{Vector{Float32}}(undef, length(O))
        bbao_vecs = Vector{Vector{Float32}}(undef, length(O))
        trans_probs = dropdims(sum([pdf(transition(pomdp, S[is], a), sp) * b.b[is] for sp in S, is in not_terminals], dims=2), dims=2)
        if !isempty(terminals) trans_probs[terminals] .+= b.b[terminals] end

        for o in O
            # update beliefs
            obs_probs = pdf.(map(sp -> observation(pomdp, a, sp), S), [o])
            bâ€² = obs_probs .* trans_probs

            if sum(bâ€²) > 0.
                bâ€² = DiscreteBelief(pomdp, b.state_list, belief_norm(pomdp, b.b, bâ€², terminals, not_terminals))
            else
                bâ€² = DiscreteBelief(pomdp, b.state_list, zeros(length(S)))
            end

            # extract optimal alpha vector at resulting belief
            # Î“ao[obsindex(pomdp, o)] = _argmax(Î± -> dot(Î±,bâ€².b), Î“)
            bao_vec = convert_s(Vector, bâ€², mdp)
            Î±Q = reshape(value(Ï€.Ï€, bao_vec), (ns, na))
            idx = argmax(map(Î±a -> Î±a â‹… bao_vec, eachcol(Î±Q)))
            # idx = argmax(reshape(bao_vec * Î±Q, na))
            Î“ao[obsindex(pomdp, o)] = Î±Q[:, idx]
            bbao_vecs[obsindex(pomdp, o)] = bao_vec
        end

        poba(o) = sum(pdf(b, s) * sum(pdf(transition(pomdp, s, a), sp) * pdf(observation(pomdp, s, a, sp), o) for sp in S) for s in S)

        Î± = zeros(Float32, length(S))
        for s in S
            idx = stateindex(pomdp, s)
            if bvec[idx] â‰ˆ zero(bvec[idx])
                Î±[idx] = value(Ï€, bvec, a_oh)[idx]
            else
                # is = abs(bvec[idx]) < sqrt(eps()) ? 0. : (bpvec[idx] / bvec[idx])
                v = r(s,a)
                if !isterminal(pomdp, s)
                    dummy = 0f0
                    for (i, o) in enumerate(O)
                        bpvec = bbao_vecs[i]
                        Î±_bp = Î“ao[i]
                        is = bpvec[idx] / bvec[idx]
                        # lb = min(is, 1f1)
                        lb = min(is, 1f10)
                        # lb = is
                        po = convert(Float32, poba(o))
                        v += Î³ * po * lb * Î±_bp[idx]
                        dummy += po
                    end
                    @assert dummy â‰ˆ 1f0
                end
                @assert isfinite(v) idx, bvec, bpvec, lb, v, Î±_bp, Î±_bp[idx]
                Î±[idx] = v
            end
        end

        # find the optimal alpha vector
        # idx = argmax(map(Î±a -> Î±a â‹… b.b, Î“a))
        # alphavec = AlphaVec(Î“a[idx], A[idx])
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_targetImpSampSmoothed(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)
    ns = length(S)
    na = length(A)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]))) do (bvec, a_oh)
        b = convert_s(DiscreteBelief, collect(bvec), mdp)

        @assert length(bvec) == length(states(pomdp))
        @assert length(a_oh) == length(actions(pomdp))

        not_terminals = [stateindex(pomdp, s) for s in S if !isterminal(pomdp, s)]
        terminals = [stateindex(pomdp, s) for s in S if isterminal(pomdp, s)]

        a = A[argmax(a_oh)]

        Î“ao = Vector{Vector{Float32}}(undef, length(O))
        bbao_vecs = Vector{Vector{Float32}}(undef, length(O))
        trans_probs = dropdims(sum([pdf(transition(pomdp, S[is], a), sp) * b.b[is] for sp in S, is in not_terminals], dims=2), dims=2)
        if !isempty(terminals) trans_probs[terminals] .+= b.b[terminals] end

        for o in O
            # update beliefs
            obs_probs = pdf.(map(sp -> observation(pomdp, a, sp), S), [o])
            bâ€² = obs_probs .* trans_probs

            if sum(bâ€²) > 0.
                bâ€² = DiscreteBelief(pomdp, b.state_list, belief_norm(pomdp, b.b, bâ€², terminals, not_terminals))
            else
                bâ€² = DiscreteBelief(pomdp, b.state_list, zeros(length(S)))
            end

            # extract optimal alpha vector at resulting belief
            # Î“ao[obsindex(pomdp, o)] = _argmax(Î± -> dot(Î±,bâ€².b), Î“)
            bao_vec = convert_s(Vector, bâ€², mdp)
            Î±Q = reshape(value(Ï€.Ï€, bao_vec), (ns, na))
            idx = argmax(map(Î±a -> Î±a â‹… bao_vec, eachcol(Î±Q)))
            # idx = argmax(reshape(bao_vec * Î±Q, na))
            Î“ao[obsindex(pomdp, o)] = Î±Q[:, idx]
            bbao_vecs[obsindex(pomdp, o)] = bao_vec
        end

        poba(o) = sum(pdf(b, s) * sum(pdf(transition(pomdp, s, a), sp) * pdf(observation(pomdp, s, a, sp), o) for sp in S) for s in S)

        Î± = zeros(Float32, length(S))
        for s in S
            idx = stateindex(pomdp, s)
            if bvec[idx] â‰ˆ zero(bvec[idx])
                Î±[idx] = value(Ï€, bvec, a_oh)[idx]
            else
                # is = abs(bvec[idx]) < sqrt(eps()) ? 0. : (bpvec[idx] / bvec[idx])
                v = r(s,a)
                if !isterminal(pomdp, s)
                    dummy = 0f0
                    for (i, o) in enumerate(O)
                        bpvec = bbao_vecs[i]
                        Î±_bp = Î“ao[i]
                        is = bpvec[idx] / bvec[idx]
                        # lb = min(is, 1f1)
                        lb = min(is, 1f10)
                        # lb = is
                        po = convert(Float32, poba(o))
                        v += Î³ * po * lb * Î±_bp[idx]
                        dummy += po
                    end
                    @assert dummy â‰ˆ 1f0
                end
                @assert isfinite(v) idx, bvec, bpvec, lb, v, Î±_bp, Î±_bp[idx]
                Î±[idx] = v
            end
        end
        Î± .= bvec .* Î± + (1f0 .- bvec) .* value(Ï€, bvec, a_oh)

        # find the optimal alpha vector
        # idx = argmax(map(Î±a -> Î±a â‹… b.b, Î“a))
        # alphavec = AlphaVec(Î“a[idx], A[idx])
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_targetSampledImpSamp(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)
    ns = length(S)
    na = length(A)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]))) do (bvec, a_oh)
        b = convert_s(DiscreteBelief, collect(bvec), mdp)

        @assert length(bvec) == length(states(pomdp))
        @assert length(a_oh) == length(actions(pomdp))

        not_terminals = [stateindex(pomdp, s) for s in S if !isterminal(pomdp, s)]
        terminals = [stateindex(pomdp, s) for s in S if isterminal(pomdp, s)]

        a = A[argmax(a_oh)]

        Î“ao = Vector{Vector{Float32}}(undef, length(O))
        bbao_vecs = Vector{Vector{Float32}}(undef, length(O))
        poba = zeros(Float32, length(O))
        trans_probs = dropdims(sum([pdf(transition(pomdp, S[is], a), sp) * b.b[is] for sp in S, is in not_terminals], dims=2), dims=2)
        if !isempty(terminals) trans_probs[terminals] .+= b.b[terminals] end

        for o in O
            # update beliefs
            obs_probs = pdf.(map(sp -> observation(pomdp, a, sp), S), [o])
            bâ€² = obs_probs .* trans_probs

            if sum(bâ€²) > 0.
                bâ€² = DiscreteBelief(pomdp, b.state_list, belief_norm(pomdp, b.b, bâ€², terminals, not_terminals))
            else
                bâ€² = DiscreteBelief(pomdp, b.state_list, zeros(length(S)))
            end

            # extract optimal alpha vector at resulting belief
            # Î“ao[obsindex(pomdp, o)] = _argmax(Î± -> dot(Î±,bâ€².b), Î“)
            bao_vec = convert_s(Vector, bâ€², mdp)
            Î±Q = reshape(value(Ï€.Ï€, bao_vec), (ns, na))
            idx = argmax(map(Î±a -> Î±a â‹… bao_vec, eachcol(Î±Q)))
            # idx = argmax(reshape(bao_vec * Î±Q, na))
            Î“ao[obsindex(pomdp, o)] = Î±Q[:, idx]
            bbao_vecs[obsindex(pomdp, o)] = bao_vec
            poba[obsindex(pomdp, o)] = sum(pdf(b, s) * sum(pdf(transition(pomdp, s, a), sp) * pdf(observation(pomdp, s, a, sp), o) for sp in S) for s in S)
        end

        Î± = zeros(Float32, length(S))
        for s in S
            idx = stateindex(pomdp, s)
            if bvec[idx] â‰ˆ zero(bvec[idx])
                Î±[idx] = value(Ï€, bvec, a_oh)[idx]
            else
                v = r(s,a)
                if !isterminal(pomdp, s)
                    for _ in 1:Ï€.m
                        o = @gen(:o)(pomdp, rand(b), a)
                        bpvec = bbao_vecs[obsindex(pomdp, o)]
                        Î±_bp = Î“ao[obsindex(pomdp, o)]
                        is = bpvec[idx] / bvec[idx]
                        lb = min(is, 10f0)
                        po = convert(Float32, 1/Ï€.m)
                        v += Î³ * po * lb * Î±_bp[idx]
                    end
                end
                @assert isfinite(v) idx, bvec, bpvec, lb, v, Î±_bp, Î±_bp[idx]
                Î±[idx] = v
            end
        end

        # find the optimal alpha vector
        # idx = argmax(map(Î±a -> Î±a â‹… b.b, Î“a))
        # alphavec = AlphaVec(Î“a[idx], A[idx])
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_modelFree(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    r = StateActionReward(pomdp)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:sp]))) do (bvec, a_oh, bpvec)
        @assert length(bvec) == 2
        a = A[argmax(a_oh)]
        Î±_bp  = best_value(Ï€, bpvec)
        @assert length(Î±_bp) == length(bpvec)

        Î± = zeros(Float32, length(S))
        for s in S
            idx = stateindex(pomdp, s)
            is = abs(bvec[idx]) < sqrt(eps()) ? 0. : (bpvec[idx] / bvec[idx])
            v = r(s,a) + (!isterminal(pomdp, s) ? (Î³ * is * Î±_bp[idx]) : 0.)
            @assert isfinite(v) idx, bvec, bpvec, is, v, Î±_bp, Î±_bp[idx]
            Î±[stateindex(pomdp, s)] = v
        end
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_modelFreeClamped(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    r = StateActionReward(pomdp)

    Ïµ = 0.2

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:sp]))) do (bvec, a_oh, bpvec)
        @assert length(bvec) == 2
        a = A[argmax(a_oh)]
        Î±_bp  = best_value(Ï€, bpvec)
        @assert length(Î±_bp) == length(bpvec)

        Î± = zeros(Float32, length(S))
        for s in S
            idx = stateindex(pomdp, s)
            # is = abs(bvec[idx]) < sqrt(eps()) ? 0. : (bpvec[idx] / bvec[idx])
            v = r(s,a)
            if !isterminal(pomdp, s)
                is = bpvec[idx] / bvec[idx]
                lb = isnan(is) ? one(is) : clamp(is, 1-Ïµ, 1+Ïµ)
                v += Î³ * lb * Î±_bp[idx]
            end
            @assert isfinite(v) idx, bvec, bpvec, lb, v, Î±_bp, Î±_bp[idx]
            Î±[stateindex(pomdp, s)] = v
        end
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

# TODO:
# - weighed clampled min
# - Use other beliefs in update (dont use value(bbao) but argmax alpha * value(b') for multiple b')
#

function alphaDQN_modelFreeClampedMin(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    r = StateActionReward(pomdp)

    Ïµ = 0.2

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:sp]))) do (bvec, a_oh, bpvec)
        @assert length(bvec) == 2
        a = A[argmax(a_oh)]
        Î±_bp  = best_value(Ï€, bpvec)
        @assert length(Î±_bp) == length(bpvec)

        Î± = zeros(Float32, length(S))
        for s in S
            idx = stateindex(pomdp, s)
            # is = abs(bvec[idx]) < sqrt(eps()) ? 0. : (bpvec[idx] / bvec[idx])
            v = r(s,a)
            if !isterminal(pomdp, s)
                is = bpvec[idx] / bvec[idx]
                lb = isfinite(is) ? one(is) : min(is * Î±_bp[idx], clamp(is, 1-Ïµ, 1+Ïµ) * Î±_bp[idx])
                v += Î³ * lb
            end
            @assert isfinite(v) idx, bvec, bpvec, is, v, lb, Î±_bp, Î±_bp[idx]
            Î±[stateindex(pomdp, s)] = v
        end
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_modelFreeWeighted(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    r = StateActionReward(pomdp)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:sp]))) do (bvec, a_oh, bpvec)
        @assert length(bvec) == 2
        a = A[argmax(a_oh)]
        Î±_bp  = best_value(Ï€, bpvec)
        @assert length(Î±_bp) == length(bpvec)

        Î± = zeros(Float32, length(S))
        for s in S
            idx = stateindex(pomdp, s)
            is = abs(bvec[idx]) < sqrt(eps()) ? 0. : (bpvec[idx] / bvec[idx])
            v = r(s,a) + (!isterminal(pomdp, s) ? (Î³ * is * Î±_bp[idx]) : 0.)
            Î±[stateindex(pomdp, s)] = v
        end
        Î± .= bvec .* Î± + (1f0 .- bvec) .* value(Ï€, bvec, a_oh)
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_modelFreeWeightedClamped(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    r = StateActionReward(pomdp)

    Ïµ = 0.2

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:sp]))) do (bvec, a_oh, bpvec)
        @assert length(bvec) == 2
        a = A[argmax(a_oh)]
        Î±_bp  = best_value(Ï€, bpvec)
        @assert length(Î±_bp) == length(bpvec)

        Î± = zeros(Float32, length(S))
        for s in S
            idx = stateindex(pomdp, s)
            # is = abs(bvec[idx]) < sqrt(eps()) ? 0. : (bpvec[idx] / bvec[idx])
            v = r(s,a)
            if !isterminal(pomdp, s)
                is = bpvec[idx] / bvec[idx]
                lb = isnan(is) ? one(is) : clamp(is, 1-Ïµ, 1+Ïµ)
                v += Î³ * lb * Î±_bp[idx]
            end
            @assert isfinite(v) idx, bvec, bpvec, lb, v, Î±_bp, Î±_bp[idx]
            Î±[stateindex(pomdp, s)] = v
        end
        Î± .= bvec .* Î± + (1f0 .- bvec) .* value(Ï€, bvec, a_oh)
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_modelFreeUpperClamped(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    r = StateActionReward(pomdp)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:sp]))) do (bvec, a_oh, bpvec)
        @assert length(bvec) == 2
        a = A[argmax(a_oh)]
        Î±_bp  = best_value(Ï€, bpvec)
        @assert length(Î±_bp) == length(bpvec)

        Î± = zeros(Float32, length(S))
        for s in S
            idx = stateindex(pomdp, s)
            if bvec[idx] â‰ˆ zero(bvec[idx])
                Î±[stateindex(pomdp, s)] = value(Ï€, bvec, a_oh)[idx]
            else
                # is = abs(bvec[idx]) < sqrt(eps()) ? 0. : (bpvec[idx] / bvec[idx])
                v = r(s,a)
                if !isterminal(pomdp, s)
                    is = bpvec[idx] / bvec[idx]
                    lb = min(is, 10f0)
                    v += Î³ * lb * Î±_bp[idx]
                end
                @assert isfinite(v) idx, bvec, bpvec, lb, v, Î±_bp, Î±_bp[idx]
                Î±[stateindex(pomdp, s)] = v
            end
        end
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end
