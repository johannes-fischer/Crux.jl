
function alphaDQN_target(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)
    ns = length(S)
    na = length(A)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]))) do (s, a_oh)
        b = convert_s(DiscreteBelief, collect(s), mdp)

        @assert length(s) == length(states(pomdp))
        @assert length(a_oh) == length(actions(pomdp))

        not_terminals = [stateindex(pomdp, s) for s in S if !isterminal(pomdp, s)]
        terminals = [stateindex(pomdp, s) for s in S if isterminal(pomdp, s)]

        a = A[argmax(a_oh)]

        Î“ao = Vector{Vector{Float32}}(undef, length(O))
        trans_probs = dropdims(sum([pdf(transition(pomdp, S[is], a), sp) * b.b[is] for sp in S, is in not_terminals], dims=2), dims=2)
        if !isempty(terminals) trans_probs[terminals] .+= b.b[terminals] end

        for o in O
            # update beliefs
            obs_probs = pdf.(map(sp -> observation(pomdp, a, sp), S), [o])
            bâ€² = obs_probs .* trans_probs

            if sum(bâ€²) > 0.
                bâ€² = DiscreteBelief(pomdp, b.state_list, belief_norm(pomdp, b.b, bâ€², terminals, not_terminals))
            else
                bâ€² = DiscreteBelief(pomdp, b.state_list, zeros(length(S)))
            end

            # extract optimal alpha vector at resulting belief
            # Î“ao[obsindex(pomdp, o)] = _argmax(Î± -> dot(Î±,bâ€².b), Î“)
            bao_vec = convert_s(Vector, bâ€², mdp)
            Î±Q = reshape(value(Ï€.Ï€, bao_vec), (ns, na))
            idx = argmax(map(Î±a -> Î±a â‹… bao_vec, eachcol(Î±Q)))
            # alphavec = AlphaVec(Î“a[idx], A[idx])
            # idx = argmax(reshape(bao_vec * Î±Q, na))
            Î“ao[obsindex(pomdp, o)] = Î±Q[:, idx]
        end

        # construct new alpha vectors
        Î± = Float32[r(s, a) + (!isterminal(pomdp, s) ? (Î³ * sum(pdf(transition(pomdp, s, a), sp) * pdf(observation(pomdp, s, a, sp), o) * Î“ao[i][j]
                                        for (j, sp) in enumerate(S), (i, o) in enumerate(O))) : 0.)
                                        for s in S]

        # find the optimal alpha vector
        # idx = argmax(map(Î±a -> Î±a â‹… b.b, Î“a))
        # alphavec = AlphaVec(Î“a[idx], A[idx])
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_target_generalize(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)
    ns = length(S)
    na = length(A)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]))) do (s, a_oh)
        b = convert_s(DiscreteBelief, collect(s), mdp)

        @assert length(s) == length(states(pomdp))
        @assert length(a_oh) == length(actions(pomdp))

        not_terminals = [stateindex(pomdp, s) for s in S if !isterminal(pomdp, s)]
        terminals = [stateindex(pomdp, s) for s in S if isterminal(pomdp, s)]

        a = A[argmax(a_oh)]

        Î“ao = Vector{Vector{Float32}}(undef, length(O))
        trans_probs = dropdims(sum([pdf(transition(pomdp, S[is], a), sp) * b.b[is] for sp in S, is in not_terminals], dims=2), dims=2)
        if !isempty(terminals) trans_probs[terminals] .+= b.b[terminals] end

        B_discretization = 100
        na = length(A)
        Î“length = na * (B_discretization + length(O))
        Î“net = Vector{Vector{Float64}}(undef, Î“length)
        i = 1

        for o in O
            # update beliefs
            obs_probs = pdf.(map(sp -> observation(pomdp, a, sp), S), [o])
            bâ€² = obs_probs .* trans_probs

            if sum(bâ€²) > 0.
                bâ€² = DiscreteBelief(pomdp, b.state_list, belief_norm(pomdp, b.b, bâ€², terminals, not_terminals))
            else
                bâ€² = DiscreteBelief(pomdp, b.state_list, zeros(length(S)))
            end

            # extract optimal alpha vector at resulting belief
            # Î“ao[obsindex(pomdp, o)] = _argmax(Î± -> dot(Î±,bâ€².b), Î“)
            bao_vec = convert_s(Vector, bâ€², mdp)
            Î±Q = reshape(value(Ï€.Ï€, bao_vec), (ns, na))
            Î“net[i:i+na-1] = collect(eachcol(Î±Q))
            i += na
        end
        for x in LinRange(0, 1, B_discretization)
            @assert i <= Î“length
            bao_vec = [x, 1-x]
            Î±Q = reshape(value(Ï€.Ï€, bao_vec), (ns, na))
            Î“net[i:i+na-1] = collect(eachcol(Î±Q))
            i += na
        end

        for o in O
            # update beliefs
            obs_probs = pdf.(map(sp -> observation(pomdp, a, sp), S), [o])
            bâ€² = obs_probs .* trans_probs

            if sum(bâ€²) > 0.
                bâ€² = DiscreteBelief(pomdp, b.state_list, belief_norm(pomdp, b.b, bâ€², terminals, not_terminals))
            else
                bâ€² = DiscreteBelief(pomdp, b.state_list, zeros(length(S)))
            end

            # # extract optimal alpha vector at resulting belief
            # # Î“ao[obsindex(pomdp, o)] = _argmax(Î± -> dot(Î±,bâ€².b), Î“)
            # bao_vec = convert_s(Vector, bâ€², mdp)
            # Î±Q = reshape(value(Ï€.Ï€, bao_vec), (ns, na))
            # idx = argmax(map(Î±a -> Î±a â‹… bao_vec, eachcol(Î±Q)))
            # # alphavec = AlphaVec(Î“a[idx], A[idx])
            # # idx = argmax(reshape(bao_vec * Î±Q, na))
            # Î“ao[obsindex(pomdp, o)] = Î±Q[:, idx]
            Î“ao[obsindex(pomdp, o)] = _argmax(Î± -> dot(Î±,bâ€².b), Î“net)
        end

        # construct new alpha vectors
        Î± = Float32[r(s, a) + (!isterminal(pomdp, s) ? (Î³ * sum(pdf(transition(pomdp, s, a), sp) * pdf(observation(pomdp, s, a, sp), o) * Î“ao[i][j]
                                        for (j, sp) in enumerate(S), (i, o) in enumerate(O))) : 0.)
                                        for s in S]

        # find the optimal alpha vector
        # idx = argmax(map(Î±a -> Î±a â‹… b.b, Î“a))
        # alphavec = AlphaVec(Î“a[idx], A[idx])
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_sampleTarget(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)
    ns = length(S)
    na = length(A)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]))) do (s, a_oh)
        B = statetype(mdp)
        b = convert_s(B, collect(s), mdp)

        not_terminals = [stateindex(pomdp, s) for s in S if !isterminal(pomdp, s)]
        terminals = [stateindex(pomdp, s) for s in S if isterminal(pomdp, s)]

        a = A[argmax(a_oh)]

        Î“ao = Vector{Vector{Float32}}(undef, length(O))
        trans_probs = dropdims(sum([pdf(transition(pomdp, S[is], a), sp) * b.b[is] for sp in S, is in not_terminals], dims=2), dims=2)
        if !isempty(terminals) trans_probs[terminals] .+= b.b[terminals] end

        for o in O
            # update beliefs
            obs_probs = pdf.(map(sp -> observation(pomdp, a, sp), S), [o])
            bâ€² = obs_probs .* trans_probs

            if sum(bâ€²) > 0.
                bâ€² = DiscreteBelief(pomdp, b.state_list, belief_norm(pomdp, b.b, bâ€², terminals, not_terminals))
            else
                bâ€² = DiscreteBelief(pomdp, b.state_list, zeros(ns))
            end

            # extract optimal alpha vector at resulting belief
            bao_vec = convert_s(Vector, bâ€², mdp)
            Î±Q = reshape(value(Ï€.Ï€, bao_vec), (ns, na))
            idx = argmax(map(Î±a -> Î±a â‹… bao_vec, eachcol(Î±Q)))
            Î“ao[obsindex(pomdp, o)] = Î±Q[:, idx]
        end

        # construct new alpha vectors
        Î± = zeros(Float32, length(S))
        for s in S
            for _ in 1:Ï€.m
                sp, o, r = @gen(:sp,:o,:r)(pomdp, s, a)
                Î±o = Î“ao[obsindex(pomdp, o)]
                v = r + (!isterminal(pomdp, s) ? (Î³ * Î±o[stateindex(pomdp, sp)]) : 0.)
                Î±[stateindex(pomdp, s)] += v / Ï€.m
            end
        end
        Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_weightedSampleTarget(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)
    ns = length(S)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:o]), eachcol(ğ’Ÿ[:sp]))) do (b_vec, a_oh, ovec, bp_vec)
        o = convert_o(obstype(pomdp), collect(ovec), mdp.pomdp)

        a = A[argmax(a_oh)]

        # extract optimal alpha vector at resulting belief
        Î±Q = reshape(value(Ï€.Ï€, bp_vec), (ns, na))
        idx = argmax(map(Î±a -> Î±a â‹… bao_vec, eachcol(Î±Q)))
        Î±o = Î±Q[:, idx]

        # construct new alpha vectors
        Î± = zeros(length(S))
        for s in S
            weights = Vector{Float64}(undef, Ï€.m)
            values = Vector{Float64}(undef, Ï€.m)
            Î±[stateindex(pomdp, s)] = r(s, a)
            if !isterminal(pomdp, s)
                for i in 1:Ï€.m
                    sp = @gen(:sp)(pomdp, s, a)
                    weights[i] = obs_weight(pomdp, s, a, sp, o)
                    values[i] = Î±o[stateindex(pomdp, sp)]
                end
                Î±[stateindex(pomdp, s)] += Î³ * dot(weights, values) / sum(weights)
            end
        end
        return Î±
    end
    reduce(hcat, alphas)
end

function alphaDQN_weightedSampleTargetAllBelief(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)
    ns = length(S)

    B_discretization = 100
    na = length(A)
    Î“length = na * B_discretization
    Î“net = Vector{Vector{Float64}}(undef, Î“length)
    i=1
    for x in LinRange(0, 1, B_discretization)
        @assert i <= Î“length
        bao_vec = [x, 1-x]
        Î±Q = reshape(value(Ï€.Ï€, bao_vec), (ns, na))
        Î“net[i:i+na-1] = collect(eachcol(Î±Q))
        i += na
    end

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:o]), eachcol(ğ’Ÿ[:sp]))) do (b_vec, a_oh, ovec, bp_vec)
        o = convert_o(obstype(pomdp), collect(ovec), mdp.pomdp)

        a = A[argmax(a_oh)]

        bpvec = collect(spvec)
        Î±_all = _argmax(Î± -> dot(Î±, bpvec), Î“net)

        # extract optimal alpha vector at resulting belief
        Î±Q = reshape(value(Ï€.Ï€, bp_vec), (ns, na))
        Î±o = _argmax(Î±a -> Î±a â‹… bpvec, collect(eachcol(Î±Q)))

        if dot(Î±_all, bpvec) > dot(Î±o, bpvec)
            Î±o = Î±_all
        end

        # construct new alpha vectors
        Î± = zeros(length(S))
        for s in S
            weights = Vector{Float64}(undef, Ï€.m)
            values = Vector{Float64}(undef, Ï€.m)
            Î±[stateindex(pomdp, s)] = r(s, a)
            if !isterminal(pomdp, s)
                for i in 1:Ï€.m
                    sp = @gen(:sp)(pomdp, s, a)
                    weights[i] = obs_weight(pomdp, s, a, sp, o)
                    values[i] = Î±o[stateindex(pomdp, sp)]
                end
                Î±[stateindex(pomdp, s)] += Î³ * dot(weights, values) / sum(weights)
            end
        end
        return Î±
    end
    reduce(hcat, alphas)
end

function alphaDQN_singleSampleTarget(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    B = statetype(mdp)
    r = StateActionReward(pomdp)
    ns = length(S)
    na = length(A)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]))) do (svec, a_oh)
        b = convert_s(B, collect(svec), mdp)

        a = A[argmax(a_oh)]

        # construct new alpha vectors
        Î± = value(Ï€, svec, a_oh)

        s = rand(b)
        sp, o, r = @gen(:sp,:o,:r)(pomdp, s, a)

        bp = POMDPs.update(mdp.updater, b, a, o)
        bpvec = convert_s(Vector, bp, mdp)

        Î±Q = reshape(value(Ï€.Ï€, bpvec), (ns, na))
        idx = argmax(map(Î±a -> Î±a â‹… bpvec, eachcol(Î±Q)))
        Î±o = Î±Q[:, idx]
        v = r + (!isterminal(pomdp, s) ? (Î³ * Î±o[stateindex(pomdp, sp)]) : 0.)
        Î±[stateindex(pomdp, s)] = v
        Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_weightedSampleTarget(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    B = statetype(mdp)
    r = StateActionReward(pomdp)
    ns = length(S)
    na = length(A)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:s_pomdp]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:o]), eachcol(ğ’Ÿ[:sp]), eachcol(ğ’Ÿ[:sp_pomdp]), ğ’Ÿ[:r])) do (svec, s_pomdp_vec, a_oh, ovec, spvec, sp_pomdp_vec, r)
        b = convert_s(B, collect(svec), mdp)

        a = A[argmax(a_oh)]

        # construct new alpha vectors
        Î± = value(Ï€, svec, a_oh)

        s = rand(b)
        sp, o, r = @gen(:sp,:o,:r)(pomdp, s, a)

        bp = POMDPs.update(mdp.updater, b, a, o)
        bpvec = convert_s(Vector, bp, mdp)

        Î±Q = reshape(value(Ï€.Ï€, bpvec), (ns, na))
        idx = argmax(map(Î±a -> Î±a â‹… bpvec, eachcol(Î±Q)))
        Î±o = Î±Q[:, idx]
        v = r + (!isterminal(pomdp, s) ? (Î³ * Î±o[stateindex(pomdp, sp)]) : 0.)
        Î±[stateindex(pomdp, s)] = v
        Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_modelFreeTrueStateBackups2(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    B = statetype(mdp)
    r = StateActionReward(pomdp)
    ns = length(S)
    na = length(A)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:s_pomdp]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:o]), eachcol(ğ’Ÿ[:sp]), eachcol(ğ’Ÿ[:sp_pomdp]), ğ’Ÿ[:r])) do (svec, s_pomdp_vec, a_oh, ovec, spvec, sp_pomdp_vec, r)
        # b = convert_s(B, collect(svec), mdp)

        # a = A[argmax(a_oh)]

        # construct new alpha vectors
        Î± = value(Ï€, svec, a_oh)

        s = convert_s(statetype(pomdp), collect(s_pomdp_vec), pomdp)
        sp = convert_s(statetype(pomdp), collect(sp_pomdp_vec), pomdp)
        # o = convert_o(obstype(pomdp), collect(ovec), mdp.pomdp)

        # bp = POMDPs.update(mdp.updater, b, a, o)
        # bpvec = convert_s(Vector, bp, mdp)
        bpvec = collect(spvec)

        Î±Q = reshape(value(Ï€.Ï€, bpvec), (ns, na))
        idx = argmax(map(Î±a -> Î±a â‹… bpvec, eachcol(Î±Q)))
        Î±o = Î±Q[:, idx]
        v = r + (!isterminal(pomdp, s) ? (Î³ * Î±o[stateindex(pomdp, sp)]) : 0.)
        Î±[stateindex(pomdp, s)] = v
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_modelFreeTrueStateBackups2AllBelief(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    B = statetype(mdp)
    r = StateActionReward(pomdp)
    ns = length(S)
    na = length(A)

    B_discretization = 100
    na = length(A)
    Î“length = na * B_discretization
    Î“net = Vector{Vector{Float64}}(undef, Î“length)
    i=1
    for x in LinRange(0, 1, B_discretization)
        @assert i <= Î“length
        bao_vec = [x, 1-x]
        Î±Q = reshape(value(Ï€.Ï€, bao_vec), (ns, na))
        Î“net[i:i+na-1] = collect(eachcol(Î±Q))
        i += na
    end

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:s_pomdp]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:o]), eachcol(ğ’Ÿ[:sp]), eachcol(ğ’Ÿ[:sp_pomdp]), ğ’Ÿ[:r])) do (svec, s_pomdp_vec, a_oh, ovec, spvec, sp_pomdp_vec, r)
        # b = convert_s(B, collect(svec), mdp)

        # a = A[argmax(a_oh)]

        # construct new alpha vectors
        Î± = value(Ï€, svec, a_oh)

        s = convert_s(statetype(pomdp), collect(s_pomdp_vec), pomdp)
        sp = convert_s(statetype(pomdp), collect(sp_pomdp_vec), pomdp)
        # o = convert_o(obstype(pomdp), collect(ovec), mdp.pomdp)

        # bp = POMDPs.update(mdp.updater, b, a, o)
        # bpvec = convert_s(Vector, bp, mdp)
        bpvec = collect(spvec)
        Î±_all = _argmax(Î± -> dot(Î±, bpvec), Î“net)

        Î±Q = reshape(value(Ï€.Ï€, bpvec), (ns, na))
        Î±o = _argmax(Î±a -> Î±a â‹… bpvec, collect(eachcol(Î±Q)))

        if dot(Î±_all, bpvec) > dot(Î±o, bpvec)
            Î±o = Î±_all
        end

        v = r + (!isterminal(pomdp, s) ? (Î³ * Î±o[stateindex(pomdp, sp)]) : 0.)
        sidx = stateindex(pomdp, s)
        Î±[sidx] = svec[sidx] * v + (1 - svec[sidx]) * Î±[sidx] # weighting happens here!
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_modelFreeStateBackups(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)
    ns = length(S)
    na = length(A)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:o]))) do (svec, a_oh, ovec)
        B = statetype(mdp)
        b = convert_s(B, collect(svec), mdp)
        o = convert_o(obstype(pomdp), collect(ovec), mdp.pomdp)

        a = A[argmax(a_oh)]

        # construct new alpha vectors
        Î± = zeros(Float32, length(S))
        for s in S
            s_base = zeros(length(S))
            s_base[stateindex(pomdp, s)] = 1.
            bs = convert_s(B, s_base, mdp)
            bp = POMDPs.update(mdp.updater, bs, a, o)
            bpvec = convert_s(Vector, bp, mdp)
            # Î±s = value(Ï€, bpvec)
            Î±Q = reshape(value(Ï€.Ï€, bpvec), (ns, na))
            idx = argmax(map(Î±a -> Î±a â‹… bpvec, eachcol(Î±Q)))
            Î±s = Î±Q[:, idx]
            v = r(s, a) + (!isterminal(pomdp, s) ? (Î³ * dot(bpvec, Î±s)) : 0.)
            Î±[stateindex(pomdp, s)] = v
        end
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_modelFreeWeightedStateBackups(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)
    ns = length(S)
    na = length(A)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:o]))) do (svec, a_oh, ovec)
        B = statetype(mdp)
        b = convert_s(B, collect(svec), mdp)
        o = convert_o(obstype(pomdp), collect(ovec), mdp.pomdp)
        svec = convert(Vector{Float32}, svec)

        a = A[argmax(a_oh)]

        # construct new alpha vectors
        Î± = zeros(Float32, length(S))
        for s in S
            s_base = zeros(length(S))
            s_base[stateindex(pomdp, s)] = 1.
            bs = convert_s(B, s_base, mdp)
            bp = POMDPs.update(mdp.updater, bs, a, o)
            bpvec = convert_s(Vector, bp, mdp)
            # Î±s = value(Ï€, bpvec)
            Î±Q = reshape(value(Ï€.Ï€, bpvec), (ns, na))
            idx = argmax(map(Î±a -> Î±a â‹… bpvec, eachcol(Î±Q)))
            Î±s = Î±Q[:, idx]
            v = r(s, a) + (!isterminal(pomdp, s) ? (Î³ * dot(bpvec, Î±s)) : 0.)
            Î±[stateindex(pomdp, s)] = v
        end
        Î± = svec .* Î± + (1 .- svec) .* value(Ï€, svec, a_oh) # weighting happens here!
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_modelFreeTrueStateBackups(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)
    ns = length(S)
    na = length(A)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:s_pomdp]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:o]), eachcol(ğ’Ÿ[:sp_pomdp]))) do (svec, s_pomdp_vec, a_oh, ovec, sp_pomdp_vec)
        B = statetype(mdp)
        b = convert_s(B, collect(svec), mdp)
        o = convert_o(obstype(pomdp), collect(ovec), mdp.pomdp)

        a = A[argmax(a_oh)]

        # construct new alpha vectors
        Î± = value(Ï€, svec, a_oh)

        s = convert_s(statetype(pomdp), collect(s_pomdp_vec), pomdp)
        sp = convert_s(statetype(pomdp), collect(sp_pomdp_vec), pomdp)

        s_base = zeros(length(S))
        s_base[stateindex(pomdp, s)] = 1.
        bs = convert_s(B, s_base, mdp)

        bp = POMDPs.update(mdp.updater, bs, a, o)
        bpvec = convert_s(Vector, bp, mdp)
        # Î±s = value(Ï€, bpvec)
        Î±Q = reshape(value(Ï€.Ï€, bpvec), (ns, na))
        idx = argmax(map(Î±a -> Î±a â‹… bpvec, eachcol(Î±Q)))
        Î±s = Î±Q[:, idx]
        v = r(s, a) + (!isterminal(pomdp, s) ? (Î³ * Î±s[stateindex(pomdp, sp)]) : 0.)
        Î±[stateindex(pomdp, s)] = v
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_targetImpSamp(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)
    ns = length(S)
    na = length(A)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]))) do (bvec, a_oh)
        b = convert_s(DiscreteBelief, collect(bvec), mdp)

        @assert length(bvec) == length(states(pomdp))
        @assert length(a_oh) == length(actions(pomdp))

        not_terminals = [stateindex(pomdp, s) for s in S if !isterminal(pomdp, s)]
        terminals = [stateindex(pomdp, s) for s in S if isterminal(pomdp, s)]

        a = A[argmax(a_oh)]

        Î“ao = Vector{Vector{Float32}}(undef, length(O))
        bbao_vecs = Vector{Vector{Float32}}(undef, length(O))
        trans_probs = dropdims(sum([pdf(transition(pomdp, S[is], a), sp) * b.b[is] for sp in S, is in not_terminals], dims=2), dims=2)
        if !isempty(terminals) trans_probs[terminals] .+= b.b[terminals] end

        for o in O
            # update beliefs
            obs_probs = pdf.(map(sp -> observation(pomdp, a, sp), S), [o])
            bâ€² = obs_probs .* trans_probs

            if sum(bâ€²) > 0.
                bâ€² = DiscreteBelief(pomdp, b.state_list, belief_norm(pomdp, b.b, bâ€², terminals, not_terminals))
            else
                bâ€² = DiscreteBelief(pomdp, b.state_list, zeros(length(S)))
            end

            # extract optimal alpha vector at resulting belief
            # Î“ao[obsindex(pomdp, o)] = _argmax(Î± -> dot(Î±,bâ€².b), Î“)
            bao_vec = convert_s(Vector, bâ€², mdp)
            Î±Q = reshape(value(Ï€.Ï€, bao_vec), (ns, na))
            idx = argmax(map(Î±a -> Î±a â‹… bao_vec, eachcol(Î±Q)))
            # idx = argmax(reshape(bao_vec * Î±Q, na))
            Î“ao[obsindex(pomdp, o)] = Î±Q[:, idx]
            bbao_vecs[obsindex(pomdp, o)] = bao_vec
        end

        poba(o) = sum(pdf(b, s) * sum(pdf(transition(pomdp, s, a), sp) * pdf(observation(pomdp, s, a, sp), o) for sp in S) for s in S)

        Î± = zeros(Float32, length(S))
        for s in S
            idx = stateindex(pomdp, s)
            if bvec[idx] â‰ˆ zero(bvec[idx])
                Î±[idx] = value(Ï€, bvec, a_oh)[idx]
            else
                # is = abs(bvec[idx]) < sqrt(eps()) ? 0. : (bpvec[idx] / bvec[idx])
                v = r(s,a)
                if !isterminal(pomdp, s)
                    dummy = 0f0
                    for (i, o) in enumerate(O)
                        bpvec = bbao_vecs[i]
                        Î±_bp = Î“ao[i]
                        is = bpvec[idx] / bvec[idx]
                        # lb = min(is, 1f1)
                        lb = min(is, 1f10)
                        # lb = is
                        po = convert(Float32, poba(o))
                        v += Î³ * po * lb * Î±_bp[idx]
                        dummy += po
                    end
                    @assert dummy â‰ˆ 1f0
                end
                @assert isfinite(v) idx, bvec, bpvec, lb, v, Î±_bp, Î±_bp[idx]
                Î±[idx] = v
            end
        end

        # find the optimal alpha vector
        # idx = argmax(map(Î±a -> Î±a â‹… b.b, Î“a))
        # alphavec = AlphaVec(Î“a[idx], A[idx])
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_targetImpSampSmoothed(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)
    ns = length(S)
    na = length(A)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]))) do (bvec, a_oh)
        b = convert_s(DiscreteBelief, collect(bvec), mdp)

        @assert length(bvec) == length(states(pomdp))
        @assert length(a_oh) == length(actions(pomdp))

        not_terminals = [stateindex(pomdp, s) for s in S if !isterminal(pomdp, s)]
        terminals = [stateindex(pomdp, s) for s in S if isterminal(pomdp, s)]

        a = A[argmax(a_oh)]

        Î“ao = Vector{Vector{Float32}}(undef, length(O))
        bbao_vecs = Vector{Vector{Float32}}(undef, length(O))
        trans_probs = dropdims(sum([pdf(transition(pomdp, S[is], a), sp) * b.b[is] for sp in S, is in not_terminals], dims=2), dims=2)
        if !isempty(terminals) trans_probs[terminals] .+= b.b[terminals] end

        for o in O
            # update beliefs
            obs_probs = pdf.(map(sp -> observation(pomdp, a, sp), S), [o])
            bâ€² = obs_probs .* trans_probs

            if sum(bâ€²) > 0.
                bâ€² = DiscreteBelief(pomdp, b.state_list, belief_norm(pomdp, b.b, bâ€², terminals, not_terminals))
            else
                bâ€² = DiscreteBelief(pomdp, b.state_list, zeros(length(S)))
            end

            # extract optimal alpha vector at resulting belief
            # Î“ao[obsindex(pomdp, o)] = _argmax(Î± -> dot(Î±,bâ€².b), Î“)
            bao_vec = convert_s(Vector, bâ€², mdp)
            Î±Q = reshape(value(Ï€.Ï€, bao_vec), (ns, na))
            idx = argmax(map(Î±a -> Î±a â‹… bao_vec, eachcol(Î±Q)))
            # idx = argmax(reshape(bao_vec * Î±Q, na))
            Î“ao[obsindex(pomdp, o)] = Î±Q[:, idx]
            bbao_vecs[obsindex(pomdp, o)] = bao_vec
        end

        poba(o) = sum(pdf(b, s) * sum(pdf(transition(pomdp, s, a), sp) * pdf(observation(pomdp, s, a, sp), o) for sp in S) for s in S)

        Î± = zeros(Float32, length(S))
        for s in S
            idx = stateindex(pomdp, s)
            if bvec[idx] â‰ˆ zero(bvec[idx])
                Î±[idx] = value(Ï€, bvec, a_oh)[idx]
            else
                # is = abs(bvec[idx]) < sqrt(eps()) ? 0. : (bpvec[idx] / bvec[idx])
                v = r(s,a)
                if !isterminal(pomdp, s)
                    dummy = 0f0
                    for (i, o) in enumerate(O)
                        bpvec = bbao_vecs[i]
                        Î±_bp = Î“ao[i]
                        is = bpvec[idx] / bvec[idx]
                        # lb = min(is, 1f1)
                        lb = min(is, 1f10)
                        # lb = is
                        po = convert(Float32, poba(o))
                        v += Î³ * po * lb * Î±_bp[idx]
                        dummy += po
                    end
                    @assert dummy â‰ˆ 1f0
                end
                @assert isfinite(v) idx, bvec, bpvec, lb, v, Î±_bp, Î±_bp[idx]
                Î±[idx] = v
            end
        end
        Î± .= bvec .* Î± + (1f0 .- bvec) .* value(Ï€, bvec, a_oh)

        # find the optimal alpha vector
        # idx = argmax(map(Î±a -> Î±a â‹… b.b, Î“a))
        # alphavec = AlphaVec(Î“a[idx], A[idx])
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_targetSampledImpSamp(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    O = POMDPTools.ordered_observations(pomdp)
    r = StateActionReward(pomdp)
    ns = length(S)
    na = length(A)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]))) do (bvec, a_oh)
        b = convert_s(DiscreteBelief, collect(bvec), mdp)

        @assert length(bvec) == length(states(pomdp))
        @assert length(a_oh) == length(actions(pomdp))

        not_terminals = [stateindex(pomdp, s) for s in S if !isterminal(pomdp, s)]
        terminals = [stateindex(pomdp, s) for s in S if isterminal(pomdp, s)]

        a = A[argmax(a_oh)]

        Î“ao = Vector{Vector{Float32}}(undef, length(O))
        bbao_vecs = Vector{Vector{Float32}}(undef, length(O))
        poba = zeros(Float32, length(O))
        trans_probs = dropdims(sum([pdf(transition(pomdp, S[is], a), sp) * b.b[is] for sp in S, is in not_terminals], dims=2), dims=2)
        if !isempty(terminals) trans_probs[terminals] .+= b.b[terminals] end

        for o in O
            # update beliefs
            obs_probs = pdf.(map(sp -> observation(pomdp, a, sp), S), [o])
            bâ€² = obs_probs .* trans_probs

            if sum(bâ€²) > 0.
                bâ€² = DiscreteBelief(pomdp, b.state_list, belief_norm(pomdp, b.b, bâ€², terminals, not_terminals))
            else
                bâ€² = DiscreteBelief(pomdp, b.state_list, zeros(length(S)))
            end

            # extract optimal alpha vector at resulting belief
            # Î“ao[obsindex(pomdp, o)] = _argmax(Î± -> dot(Î±,bâ€².b), Î“)
            bao_vec = convert_s(Vector, bâ€², mdp)
            Î±Q = reshape(value(Ï€.Ï€, bao_vec), (ns, na))
            idx = argmax(map(Î±a -> Î±a â‹… bao_vec, eachcol(Î±Q)))
            # idx = argmax(reshape(bao_vec * Î±Q, na))
            Î“ao[obsindex(pomdp, o)] = Î±Q[:, idx]
            bbao_vecs[obsindex(pomdp, o)] = bao_vec
            poba[obsindex(pomdp, o)] = sum(pdf(b, s) * sum(pdf(transition(pomdp, s, a), sp) * pdf(observation(pomdp, s, a, sp), o) for sp in S) for s in S)
        end

        Î± = zeros(Float32, length(S))
        for s in S
            idx = stateindex(pomdp, s)
            if bvec[idx] â‰ˆ zero(bvec[idx])
                Î±[idx] = value(Ï€, bvec, a_oh)[idx]
            else
                v = r(s,a)
                if !isterminal(pomdp, s)
                    for _ in 1:Ï€.m
                        o = @gen(:o)(pomdp, rand(b), a)
                        bpvec = bbao_vecs[obsindex(pomdp, o)]
                        Î±_bp = Î“ao[obsindex(pomdp, o)]
                        is = bpvec[idx] / bvec[idx]
                        lb = min(is, 10f0)
                        po = convert(Float32, 1/Ï€.m)
                        v += Î³ * po * lb * Î±_bp[idx]
                    end
                end
                @assert isfinite(v) idx, bvec, bpvec, lb, v, Î±_bp, Î±_bp[idx]
                Î±[idx] = v
            end
        end

        # find the optimal alpha vector
        # idx = argmax(map(Î±a -> Î±a â‹… b.b, Î“a))
        # alphavec = AlphaVec(Î“a[idx], A[idx])
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_modelFree(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    r = StateActionReward(pomdp)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:sp]))) do (bvec, a_oh, bpvec)
        @assert length(bvec) == 2
        a = A[argmax(a_oh)]
        Î±_bp  = best_value(Ï€, bpvec)
        @assert length(Î±_bp) == length(bpvec)

        Î± = zeros(Float32, length(S))
        for s in S
            idx = stateindex(pomdp, s)
            is = abs(bvec[idx]) < sqrt(eps()) ? 0. : (bpvec[idx] / bvec[idx])
            v = r(s,a) + (!isterminal(pomdp, s) ? (Î³ * is * Î±_bp[idx]) : 0.)
            @assert isfinite(v) idx, bvec, bpvec, is, v, Î±_bp, Î±_bp[idx]
            Î±[stateindex(pomdp, s)] = v
        end
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_modelFreeClamped(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    r = StateActionReward(pomdp)

    Ïµ = 0.2

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:sp]))) do (bvec, a_oh, bpvec)
        @assert length(bvec) == 2
        a = A[argmax(a_oh)]
        Î±_bp  = best_value(Ï€, bpvec)
        @assert length(Î±_bp) == length(bpvec)

        Î± = zeros(Float32, length(S))
        for s in S
            idx = stateindex(pomdp, s)
            # is = abs(bvec[idx]) < sqrt(eps()) ? 0. : (bpvec[idx] / bvec[idx])
            v = r(s,a)
            if !isterminal(pomdp, s)
                is = bpvec[idx] / bvec[idx]
                lb = isnan(is) ? one(is) : clamp(is, 1-Ïµ, 1+Ïµ)
                v += Î³ * lb * Î±_bp[idx]
            end
            @assert isfinite(v) idx, bvec, bpvec, lb, v, Î±_bp, Î±_bp[idx]
            Î±[stateindex(pomdp, s)] = v
        end
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_modelFreeClampedMin(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    r = StateActionReward(pomdp)

    Ïµ = 0.2

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:sp]))) do (bvec, a_oh, bpvec)
        @assert length(bvec) == 2
        a = A[argmax(a_oh)]
        Î±_bp  = best_value(Ï€, bpvec)
        @assert length(Î±_bp) == length(bpvec)

        Î± = zeros(Float32, length(S))
        for s in S
            idx = stateindex(pomdp, s)
            # is = abs(bvec[idx]) < sqrt(eps()) ? 0. : (bpvec[idx] / bvec[idx])
            v = r(s,a)
            if !isterminal(pomdp, s)
                is = bpvec[idx] / bvec[idx]
                lb = isfinite(is) ? one(is) : min(is * Î±_bp[idx], clamp(is, 1-Ïµ, 1+Ïµ) * Î±_bp[idx])
                v += Î³ * lb
            end
            @assert isfinite(v) idx, bvec, bpvec, is, v, lb, Î±_bp, Î±_bp[idx]
            Î±[stateindex(pomdp, s)] = v
        end
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_modelFreeWeighted(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    r = StateActionReward(pomdp)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:sp]))) do (bvec, a_oh, bpvec)
        @assert length(bvec) == 2
        a = A[argmax(a_oh)]
        Î±_bp  = best_value(Ï€, bpvec)
        @assert length(Î±_bp) == length(bpvec)

        Î± = zeros(Float32, length(S))
        for s in S
            idx = stateindex(pomdp, s)
            is = abs(bvec[idx]) < sqrt(eps()) ? 0. : (bpvec[idx] / bvec[idx])
            v = r(s,a) + (!isterminal(pomdp, s) ? (Î³ * is * Î±_bp[idx]) : 0.)
            Î±[stateindex(pomdp, s)] = v
        end
        Î± .= bvec .* Î± + (1f0 .- bvec) .* value(Ï€, bvec, a_oh)
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_modelFreeWeightedClamped(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    r = StateActionReward(pomdp)

    Ïµ = 0.2

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:sp]))) do (bvec, a_oh, bpvec)
        @assert length(bvec) == 2
        a = A[argmax(a_oh)]
        Î±_bp  = best_value(Ï€, bpvec)
        @assert length(Î±_bp) == length(bpvec)

        Î± = zeros(Float32, length(S))
        for s in S
            idx = stateindex(pomdp, s)
            # is = abs(bvec[idx]) < sqrt(eps()) ? 0. : (bpvec[idx] / bvec[idx])
            v = r(s,a)
            if !isterminal(pomdp, s)
                is = bpvec[idx] / bvec[idx]
                lb = isnan(is) ? one(is) : clamp(is, 1-Ïµ, 1+Ïµ)
                v += Î³ * lb * Î±_bp[idx]
            end
            @assert isfinite(v) idx, bvec, bpvec, lb, v, Î±_bp, Î±_bp[idx]
            Î±[stateindex(pomdp, s)] = v
        end
        Î± .= bvec .* Î± + (1f0 .- bvec) .* value(Ï€, bvec, a_oh)
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end

function alphaDQN_modelFreeUpperClamped(Ï€, ğ’«, ğ’Ÿ, Î³::Float32; kwargs...)
    mdp = Ï€.mdp
    pomdp = mdp.pomdp
    S = POMDPTools.ordered_states(pomdp)
    A = POMDPTools.ordered_actions(pomdp)
    r = StateActionReward(pomdp)

    alphas = map(zip(eachcol(ğ’Ÿ[:s]), eachcol(ğ’Ÿ[:a]), eachcol(ğ’Ÿ[:sp]))) do (bvec, a_oh, bpvec)
        @assert length(bvec) == 2
        a = A[argmax(a_oh)]
        Î±_bp  = best_value(Ï€, bpvec)
        @assert length(Î±_bp) == length(bpvec)

        Î± = zeros(Float32, length(S))
        for s in S
            idx = stateindex(pomdp, s)
            if bvec[idx] â‰ˆ zero(bvec[idx])
                Î±[stateindex(pomdp, s)] = value(Ï€, bvec, a_oh)[idx]
            else
                # is = abs(bvec[idx]) < sqrt(eps()) ? 0. : (bpvec[idx] / bvec[idx])
                v = r(s,a)
                if !isterminal(pomdp, s)
                    is = bpvec[idx] / bvec[idx]
                    lb = min(is, 10f0)
                    v += Î³ * lb * Î±_bp[idx]
                end
                @assert isfinite(v) idx, bvec, bpvec, lb, v, Î±_bp, Î±_bp[idx]
                Î±[stateindex(pomdp, s)] = v
            end
        end
        return Î±
    end
    res = reduce(hcat, alphas)
    reshape(res, (length(S), 1, length(alphas)))
end
